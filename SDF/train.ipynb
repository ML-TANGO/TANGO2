{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3293802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.47.0)\n",
      "Requirement already satisfied: accelerate in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.2.0)\n",
      "Collecting peft\n",
      "  Downloading peft-0.17.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.2.0)\n",
      "Collecting trl\n",
      "  Downloading trl-0.21.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.8.4)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting huggingface_hub>=0.25.0 (from peft)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub>=0.25.0->peft)\n",
      "  Downloading hf_xet-1.1.8-cp37-abi3-macosx_11_0_arm64.whl.metadata (703 bytes)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Downloading peft-0.17.1-py3-none-any.whl (504 kB)\n",
      "Downloading trl-0.21.0-py3-none-any.whl (511 kB)\n",
      "Downloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.8-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: hf-xet, huggingface_hub, accelerate, transformers, trl, peft\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.26.5\n",
      "    Uninstalling huggingface-hub-0.26.5:\n",
      "      Successfully uninstalled huggingface-hub-0.26.5\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.2.0\n",
      "    Uninstalling accelerate-1.2.0:\n",
      "      Successfully uninstalled accelerate-1.2.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.47.0\n",
      "    Uninstalling transformers-4.47.0:\n",
      "      Successfully uninstalled transformers-4.47.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "docling-ibm-models 3.4.2 requires numpy<3.0.0,>=1.24.4; sys_platform != \"darwin\" or platform_machine != \"x86_64\", but you have numpy 1.24.3 which is incompatible.\n",
      "docling 2.31.0 requires pandas<3.0.0,>=2.1.4, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.10.1 hf-xet-1.1.8 huggingface_hub-0.34.4 peft-0.17.1 transformers-4.55.4 trl-0.21.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate peft datasets trl psutil GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a9d16b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델과 토크나이저를 로딩 중...\n",
      "LoRA 설정 중...\n",
      "훈련 가능한 파라미터:\n",
      "trainable params: 1,572,864 || all params: 1,348,044,800 || trainable%: 0.1167\n",
      "데이터셋 로딩 중...\n",
      "데이터셋 구조: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'query', 'answers', 'tools'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n",
      "훈련 데이터 샘플: {'id': 0, 'query': '현재 날짜와 시간: 2025-07-28 04:40, 하우스 상태는 온도 5.1도, 습도 77.5%, 일사량 0.06, 전등 상태: 꺼짐, 최근 관수: 13시간 전, 50L, 좌측 창문: 50%, 우측 창문: 0% 이고, 적정 환경은 온도 24.4도, 습도 71.1%, 일사량 1.26 입니다.', 'answers': '[{\"name\": \"open_left_window\", \"arguments\": {\"persent\": 0}}, {\"name\": \"light_on\", \"arguments\": {}}]', 'tools': '[{\"name\": \"open_left_window\", \"description\": \"왼쪽 창문을 주어진 퍼센트(%)만큼 엽니다. 온도를 낮추거나 환기시킬 때 사용합니다.\", \"parameters\": {\"persent\": {\"type\": \"int\", \"description\": \"열고자 하는 창문의 개방 정도(0-100%)\"}}}, {\"name\": \"open_right_window\", \"description\": \"오른쪽 창문을 주어진 퍼센트(%)만큼 엽니다. 온도를 낮추거나 환기시킬 때 사용합니다.\", \"parameters\": {\"persent\": {\"type\": \"int\", \"description\": \"열고자 하는 창문의 개방 정도(0-100%)\"}}}, {\"name\": \"supply_water\", \"description\": \"식물에게 지정된 양만큼의 물을 공급합니다. 토양이 건조하거나 습도를 높여야 할 때 사용합니다.\", \"parameters\": {\"Liter\": {\"type\": \"float\", \"description\": \"공급할 물의 양 (리터 단위)\"}}}, {\"name\": \"light_on\", \"description\": \"하우스 내부의 생장등을 켭니다. 일조량이 부족할 때 사용합니다.\", \"parameters\": {}}, {\"name\": \"light_off\", \"description\": \"하우스 내부의 생장등을 끕니다. 야간이거나 일조량이 충분할 때 사용합니다.\", \"parameters\": {}}]'}\n",
      "데이터 토크나이징 중...\n",
      "훈련 설정 중...\n",
      "트레이너 설정 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace6d302a8e34612803c06b41e77a4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메모리 모니터링을 시작합니다...\n",
      "\n",
      "[11:14:00] 시스템 메모리: 사용: 14.4GB / 전체: 32.0GB (72.6%)\n",
      "\n",
      "==================================================\n",
      "학습을 시작합니다...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:14:05] 시스템 메모리: 사용: 21.1GB / 전체: 32.0GB (94.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:14:10] 시스템 메모리: 사용: 21.7GB / 전체: 32.0GB (92.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 04:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.991400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.968700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.950600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:14:15] 시스템 메모리: 사용: 22.4GB / 전체: 32.0GB (92.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:14:20] 시스템 메모리: 사용: 22.2GB / 전체: 32.0GB (91.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:14:25] 시스템 메모리: 사용: 22.1GB / 전체: 32.0GB (90.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:14:30] 시스템 메모리: 사용: 22.7GB / 전체: 32.0GB (92.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:14:35] 시스템 메모리: 사용: 22.3GB / 전체: 32.0GB (90.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:14:40] 시스템 메모리: 사용: 22.2GB / 전체: 32.0GB (91.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:14:45] 시스템 메모리: 사용: 22.7GB / 전체: 32.0GB (92.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:14:50] 시스템 메모리: 사용: 21.9GB / 전체: 32.0GB (90.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:14:55] 시스템 메모리: 사용: 22.0GB / 전체: 32.0GB (91.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:15:00] 시스템 메모리: 사용: 22.5GB / 전체: 32.0GB (92.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:15:05] 시스템 메모리: 사용: 22.2GB / 전체: 32.0GB (91.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:15:10] 시스템 메모리: 사용: 22.5GB / 전체: 32.0GB (92.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:15:15] 시스템 메모리: 사용: 22.5GB / 전체: 32.0GB (92.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:15:20] 시스템 메모리: 사용: 22.1GB / 전체: 32.0GB (89.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:15:26] 시스템 메모리: 사용: 22.6GB / 전체: 32.0GB (91.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:15:31] 시스템 메모리: 사용: 22.2GB / 전체: 32.0GB (90.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:15:36] 시스템 메모리: 사용: 22.2GB / 전체: 32.0GB (89.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:15:41] 시스템 메모리: 사용: 22.8GB / 전체: 32.0GB (91.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:15:46] 시스템 메모리: 사용: 22.7GB / 전체: 32.0GB (91.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:15:51] 시스템 메모리: 사용: 22.4GB / 전체: 32.0GB (90.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:15:56] 시스템 메모리: 사용: 22.9GB / 전체: 32.0GB (91.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:16:01] 시스템 메모리: 사용: 22.4GB / 전체: 32.0GB (90.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:16:06] 시스템 메모리: 사용: 22.9GB / 전체: 32.0GB (91.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:16:11] 시스템 메모리: 사용: 22.7GB / 전체: 32.0GB (91.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:16:16] 시스템 메모리: 사용: 22.3GB / 전체: 32.0GB (90.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:16:21] 시스템 메모리: 사용: 22.7GB / 전체: 32.0GB (92.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:16:26] 시스템 메모리: 사용: 22.4GB / 전체: 32.0GB (91.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:16:31] 시스템 메모리: 사용: 22.2GB / 전체: 32.0GB (90.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:16:36] 시스템 메모리: 사용: 22.7GB / 전체: 32.0GB (92.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:16:41] 시스템 메모리: 사용: 22.3GB / 전체: 32.0GB (90.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:16:46] 시스템 메모리: 사용: 22.8GB / 전체: 32.0GB (92.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:16:51] 시스템 메모리: 사용: 22.4GB / 전체: 32.0GB (92.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:16:56] 시스템 메모리: 사용: 22.2GB / 전체: 32.0GB (91.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:17:01] 시스템 메모리: 사용: 22.7GB / 전체: 32.0GB (92.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:17:06] 시스템 메모리: 사용: 22.7GB / 전체: 32.0GB (91.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:17:11] 시스템 메모리: 사용: 22.1GB / 전체: 32.0GB (90.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:17:16] 시스템 메모리: 사용: 22.3GB / 전체: 32.0GB (92.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:17:21] 시스템 메모리: 사용: 22.6GB / 전체: 32.0GB (92.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:17:26] 시스템 메모리: 사용: 22.8GB / 전체: 32.0GB (91.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:17:31] 시스템 메모리: 사용: 22.6GB / 전체: 32.0GB (90.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:17:36] 시스템 메모리: 사용: 22.6GB / 전체: 32.0GB (90.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:17:41] 시스템 메모리: 사용: 23.0GB / 전체: 32.0GB (91.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:17:46] 시스템 메모리: 사용: 22.7GB / 전체: 32.0GB (89.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:17:51] 시스템 메모리: 사용: 22.6GB / 전체: 32.0GB (89.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:17:56] 시스템 메모리: 사용: 23.1GB / 전체: 32.0GB (91.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:18:01] 시스템 메모리: 사용: 22.6GB / 전체: 32.0GB (90.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:18:06] 시스템 메모리: 사용: 22.5GB / 전체: 32.0GB (89.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:18:11] 시스템 메모리: 사용: 23.1GB / 전체: 32.0GB (91.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:18:16] 시스템 메모리: 사용: 22.9GB / 전체: 32.0GB (91.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:18:21] 시스템 메모리: 사용: 22.5GB / 전체: 32.0GB (89.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:18:26] 시스템 메모리: 사용: 23.1GB / 전체: 32.0GB (92.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:18:31] 시스템 메모리: 사용: 23.1GB / 전체: 32.0GB (91.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:18:36] 시스템 메모리: 사용: 22.5GB / 전체: 32.0GB (90.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:18:41] 시스템 메모리: 사용: 23.1GB / 전체: 32.0GB (91.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11:18:46] 시스템 메모리: 사용: 22.8GB / 전체: 32.0GB (90.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "학습이 완료되었습니다!\n",
      "총 소요 시간: 4.8분\n",
      "==================================================\n",
      "\n",
      "메모리 모니터링을 중지했습니다.\n",
      "\n",
      "최종 메모리 상태:\n",
      "시스템 메모리: 21.8GB / 32.0GB (87.4%)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "import psutil\n",
    "import GPUtil\n",
    "import time\n",
    "import threading\n",
    "from datetime import datetime\n",
    "\n",
    "# 메모리 모니터링 함수\n",
    "def monitor_memory(stop_event):\n",
    "    \"\"\"실시간으로 메모리 사용량을 모니터링하는 함수\"\"\"\n",
    "    while not stop_event.is_set():\n",
    "        try:\n",
    "            # 시스템 메모리\n",
    "            memory = psutil.virtual_memory()\n",
    "            print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] 시스템 메모리: \"\n",
    "                  f\"사용: {memory.used / 1024**3:.1f}GB / \"\n",
    "                  f\"전체: {memory.total / 1024**3:.1f}GB \"\n",
    "                  f\"({memory.percent:.1f}%)\")\n",
    "            \n",
    "            # GPU 메모리 (사용 가능한 경우)\n",
    "            try:\n",
    "                gpus = GPUtil.getGPUs()\n",
    "                for i, gpu in enumerate(gpus):\n",
    "                    print(f\"[{datetime.now().strftime('%H:%M:%S')}] GPU {i}: \"\n",
    "                          f\"메모리 사용: {gpu.memoryUsed}MB / \"\n",
    "                          f\"전체: {gpu.memoryTotal}MB \"\n",
    "                          f\"({gpu.memoryUtil*100:.1f}%)\")\n",
    "            except:\n",
    "                # PyTorch로 GPU 메모리 확인\n",
    "                if torch.cuda.is_available():\n",
    "                    for i in range(torch.cuda.device_count()):\n",
    "                        allocated = torch.cuda.memory_allocated(i) / 1024**2\n",
    "                        reserved = torch.cuda.memory_reserved(i) / 1024**2\n",
    "                        total = torch.cuda.get_device_properties(i).total_memory / 1024**2\n",
    "                        print(f\"[{datetime.now().strftime('%H:%M:%S')}] GPU {i}: \"\n",
    "                              f\"할당됨: {allocated:.1f}MB / \"\n",
    "                              f\"예약됨: {reserved:.1f}MB / \"\n",
    "                              f\"전체: {total:.1f}MB\")\n",
    "            \n",
    "            time.sleep(5)  # 5초마다 업데이트\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"모니터링 오류: {e}\")\n",
    "            time.sleep(5)\n",
    "\n",
    "# Define the model name\n",
    "model_name = \"Salesforce/xLAM-1b-fc-r\"\n",
    "\n",
    "print(\"모델과 토크나이저를 로딩 중...\")\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"LoRA 설정 중...\")\n",
    "# Configure LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Get the PEFT model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Print the trainable parameters\n",
    "print(\"훈련 가능한 파라미터:\")\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# --- Data Preparation ---\n",
    "print(\"데이터셋 로딩 중...\")\n",
    "dataset = load_dataset('csv', data_files='./data/train_data_100.csv')\n",
    "\n",
    "# 데이터셋 구조 확인\n",
    "print(f\"데이터셋 구조: {dataset}\")\n",
    "print(f\"훈련 데이터 샘플: {dataset['train'][0] if len(dataset['train']) > 0 else '빈 데이터셋'}\")\n",
    "\n",
    "# 토크나이저 함수 수정\n",
    "def tokenize_function(examples):\n",
    "    # query와 answers를 조합하여 입력 텍스트 생성\n",
    "    input_texts = []\n",
    "    \n",
    "    for i in range(len(examples['query'])):\n",
    "        query = examples['query'][i]\n",
    "        answers = examples['answers'][i]\n",
    "        tools = examples['tools'][i]\n",
    "        \n",
    "        # 프롬프트 형식으로 조합\n",
    "        prompt = f\"Query: {query}\\nTools: {tools}\\nAnswer: {answers}\"\n",
    "        input_texts.append(prompt)\n",
    "    \n",
    "    # 토크나이징\n",
    "    tokenized_inputs = tokenizer(\n",
    "        input_texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    # Causal LM을 위한 labels 설정\n",
    "    tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"].copy()\n",
    "    return tokenized_inputs\n",
    "\n",
    "print(\"데이터 토크나이징 중...\")\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=dataset['train'].column_names)\n",
    "\n",
    "# Set format for PyTorch\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# --- Training Arguments ---\n",
    "print(\"훈련 설정 중...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,  # 메모리 문제 방지를 위해 줄임\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"no\",  # evaluation_strategy -> eval_strategy로 수정\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,  # 디스크 공간 절약\n",
    "    gradient_accumulation_steps=2,  # 효과적인 배치 크기 증가\n",
    "    report_to=None,  # wandb 등 외부 로깅 비활성화\n",
    ")\n",
    "\n",
    "# --- Trainer ---\n",
    "print(\"트레이너 설정 중...\")\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    ")\n",
    "\n",
    "\n",
    "# 메모리 모니터링 시작\n",
    "print(\"메모리 모니터링을 시작합니다...\")\n",
    "stop_monitoring = threading.Event()\n",
    "monitor_thread = threading.Thread(target=monitor_memory, args=(stop_monitoring,))\n",
    "monitor_thread.daemon = True\n",
    "monitor_thread.start()\n",
    "\n",
    "try:\n",
    "    # --- Start Training ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"학습을 시작합니다...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"학습이 완료되었습니다!\")\n",
    "    print(f\"총 소요 시간: {(end_time - start_time) / 60:.1f}분\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n학습 중 오류 발생: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "finally:\n",
    "    # 모니터링 중지\n",
    "    stop_monitoring.set()\n",
    "    monitor_thread.join(timeout=1)\n",
    "    print(\"\\n메모리 모니터링을 중지했습니다.\")\n",
    "\n",
    "# 최종 메모리 상태 출력\n",
    "print(\"\\n최종 메모리 상태:\")\n",
    "memory = psutil.virtual_memory()\n",
    "print(f\"시스템 메모리: {memory.used / 1024**3:.1f}GB / {memory.total / 1024**3:.1f}GB ({memory.percent:.1f}%)\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        allocated = torch.cuda.memory_allocated(i) / 1024**2\n",
    "        reserved = torch.cuda.memory_reserved(i) / 1024**2\n",
    "        total = torch.cuda.get_device_properties(i).total_memory / 1024**2\n",
    "        print(f\"GPU {i}: {allocated:.1f}MB / {reserved:.1f}MB / {total:.1f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97ae3bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_xlm_lora/tokenizer_config.json',\n",
       " './fine_tuned_xlm_lora/special_tokens_map.json',\n",
       " './fine_tuned_xlm_lora/chat_template.jinja',\n",
       " './fine_tuned_xlm_lora/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.save_pretrained(\"./fine_tuned_xlm_lora\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_xlm_lora\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Import necessary libraries\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "# from peft import LoraConfig, get_peft_model\n",
    "# from datasets import load_dataset\n",
    "# from trl import SFTTrainer # SFTTrainer is often used for supervised fine-tuning\n",
    "\n",
    "# # Define the model name\n",
    "# model_name = \"Salesforce/xLAM-1b-fc-r\"\n",
    "\n",
    "# # Load the model and tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     # Since this is a smaller model, we might not need 4-bit quantization,\n",
    "#     # but you can uncomment the following lines if you still face memory issues.\n",
    "#     # load_in_4bit=True, # Load in 4-bit\n",
    "#     # torch_dtype=torch.bfloat16, # Use bfloat16\n",
    "#     device_map=\"auto\" # Automatically map the model to available devices\n",
    "# )\n",
    "\n",
    "# # Configure LoRA\n",
    "# lora_config = LoraConfig(\n",
    "#     r=8,  # LoRA attention dimension\n",
    "#     lora_alpha=16,  # Alpha parameter for LoRA scaling\n",
    "#     lora_dropout=0.1,  # Dropout probability for LoRA layers\n",
    "#     bias=\"none\",  # Bias type for LoRA layers\n",
    "#     task_type=\"CAUSAL_LM\", # Task type for causal language modeling\n",
    "# )\n",
    "\n",
    "# # Get the PEFT model\n",
    "# model = get_peft_model(model, lora_config)\n",
    "\n",
    "# # Print the trainable parameters\n",
    "# model.print_trainable_parameters()\n",
    "\n",
    "# # --- Data Preparation ---\n",
    "# # Load your training data from the CSV file\n",
    "# dataset = load_dataset('csv', data_files='./data/train_data_100.csv')\n",
    "\n",
    "# # You need to adapt this part based on your CSV file structure.\n",
    "# # Assuming your CSV has a column named 'text' with the input sentences and a column named 'labels' with the corresponding labels.\n",
    "# # You might need to add padding or truncation depending on your data and model.\n",
    "# # For causal language modeling, the label is typically the next token, so the input text is also the target.\n",
    "# def tokenize_function(examples):\n",
    "#     # Tokenize the input text\n",
    "#     tokenized_inputs = tokenizer(\n",
    "#         examples['text'],\n",
    "#         padding=\"max_length\", # or padding=True, truncation=True, max_length=...\n",
    "#         truncation=True,\n",
    "#         return_tensors=\"pt\"\n",
    "#     )\n",
    "#     # For causal language modeling, the labels are the same as the input_ids\n",
    "#     tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"].clone()\n",
    "#     return tokenized_inputs\n",
    "\n",
    "# tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# # If you have a validation split, you would do the same for it:\n",
    "# # eval_dataset = load_dataset('csv', data_files='your_validation_data.csv')\n",
    "# # tokenized_eval_datasets = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# # Set format for PyTorch\n",
    "# tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "# # if 'eval' in tokenized_eval_datasets:\n",
    "# #     tokenized_eval_datasets['eval'].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# # --- Training Arguments ---\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./results\",  # Output directory for checkpoints and logs\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=8, # Increased batch size for smaller model\n",
    "#     per_device_eval_batch_size=8,  # Increased batch size for smaller model\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "#     evaluation_strategy=\"no\", # Set to \"epoch\" if you have an evaluation set\n",
    "#     save_strategy=\"epoch\",\n",
    "#     load_best_model_at_end=False, # Set to True if evaluation_strategy is \"epoch\"\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=10,\n",
    "# )\n",
    "\n",
    "# # --- Trainer ---\n",
    "# # Using SFTTrainer for supervised fine-tuning is often more convenient\n",
    "# trainer = SFTTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_datasets['train'], # Your training dataset\n",
    "#     # eval_dataset=tokenized_eval_datasets['eval'],   # Your evaluation dataset (optional)\n",
    "#     tokenizer=tokenizer, # Pass the tokenizer to the trainer\n",
    "#     # data_collator=data_collator, # Optional data collator\n",
    "#     # max_seq_length=..., # Optional: Set a max sequence length\n",
    "# )\n",
    "\n",
    "\n",
    "# # --- Start Training ---\n",
    "# trainer.train()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Training code updated for Salesforce/xLAM-1b-fc-r. Please run the cell to start training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
