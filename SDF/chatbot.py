# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import json
import re

# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
print("ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë”© ì¤‘...")

# ê¸°ë³¸ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
base_model_name = "Salesforce/xLAM-1b-fc-r"
tokenizer = AutoTokenizer.from_pretrained(base_model_name)
base_model = AutoModelForCausalLM.from_pretrained(
    base_model_name,
    device_map="auto",
    torch_dtype=torch.float16
)

# LoRA ì–´ëŒ‘í„° ë¡œë“œ
model = PeftModel.from_pretrained(base_model, "./fine_tuned_xlm_lora")

print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {len(model.peft_config)} ê°œì˜ LoRA ì–´ëŒ‘í„°ê°€ ë¡œë“œë¨")

# ìŠ¤ë§ˆíŠ¸í™ˆ ë„êµ¬ ì •ë³´ ì •ì˜
SMART_HOME_TOOLS = [
    {
        "name": "open_left_window",
        "description": "ì™¼ìª½ ì°½ë¬¸ì„ ì£¼ì–´ì§„ í¼ì„¼íŠ¸(%)ë§Œí¼ ì—½ë‹ˆë‹¤. ì˜¨ë„ë¥¼ ë‚®ì¶”ê±°ë‚˜ í™˜ê¸°ì‹œí‚¬ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "parameters": {"persent": {"type": "int", "description": "ì—´ê³ ì í•˜ëŠ” ì°½ë¬¸ì˜ ê°œë°© ì •ë„(0-100%)"}}
    },
    {
        "name": "open_right_window",
        "description": "ì˜¤ë¥¸ìª½ ì°½ë¬¸ì„ ì£¼ì–´ì§„ í¼ì„¼íŠ¸(%)ë§Œí¼ ì—½ë‹ˆë‹¤. ì˜¨ë„ë¥¼ ë‚®ì¶”ê±°ë‚˜ í™˜ê¸°ì‹œí‚¬ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "parameters": {"persent": {"type": "int", "description": "ì—´ê³ ì í•˜ëŠ” ì°½ë¬¸ì˜ ê°œë°© ì •ë„(0-100%)"}}
    },
    {
        "name": "supply_water",
        "description": "ì‹ë¬¼ì—ê²Œ ì§€ì •ëœ ì–‘ë§Œí¼ì˜ ë¬¼ì„ ê³µê¸‰í•©ë‹ˆë‹¤. í† ì–‘ì´ ê±´ì¡°í•˜ê±°ë‚˜ ìŠµë„ë¥¼ ë†’ì—¬ì•¼ í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "parameters": {"Liter": {"type": "float", "description": "ê³µê¸‰í•  ë¬¼ì˜ ì–‘ (ë¦¬í„° ë‹¨ìœ„)"}}
    },
    {
        "name": "light_on",
        "description": "í•˜ìš°ìŠ¤ ë‚´ë¶€ì˜ ìƒì¥ë“±ì„ ì¼­ë‹ˆë‹¤. ì¼ì¡°ëŸ‰ì´ ë¶€ì¡±í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "parameters": {}
    },
    {
        "name": "light_off",
        "description": "í•˜ìš°ìŠ¤ ë‚´ë¶€ì˜ ìƒì¥ë“±ì„ ë•ë‹ˆë‹¤. ì•¼ê°„ì´ê±°ë‚˜ ì¼ì¡°ëŸ‰ì´ ì¶©ë¶„í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "parameters": {}
    }
]

print("ìŠ¤ë§ˆíŠ¸í™ˆ ë„êµ¬ ì •ë³´:")
for tool in SMART_HOME_TOOLS:
    print(f"- {tool['name']}: {tool['description']}")

# ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_response(prompt, max_new_tokens=200):
    """í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ì…ë ¥ í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)

        # ë””ë°”ì´ìŠ¤ ì„¤ì • - MPS ëŒ€ì‹  CPU ì‚¬ìš©ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´
        device = "cpu"  # MPS ëŒ€ì‹  CPU ì‚¬ìš©
        inputs = {k: v.to(device) for k, v in inputs.items()}
        model.to(device)
        
        # ì‘ë‹µ ìƒì„±
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                num_return_sequences=1,
                temperature=0.2,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id,
                eos_token_id=tokenizer.eos_token_id,
                repetition_penalty=1.1
            )
        
        # í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # ì…ë ¥ í”„ë¡¬í”„íŠ¸ ì œê±°í•˜ê³  ì‘ë‹µë§Œ ë°˜í™˜
        response = response.replace(prompt, "").strip()
        return response
        
    except Exception as e:
        return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
    
# JSON ì‘ë‹µ íŒŒì‹± í•¨ìˆ˜
def parse_json_response(response):
    """AI ì‘ë‹µì—ì„œ JSON í˜•ì‹ì˜ ì•¡ì…˜ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # JSON ë°°ì—´ íŒ¨í„´ ì°¾ê¸°
        json_pattern = r'\[\s*\{[^\]]*\}\]'
        json_match = re.search(json_pattern, response)
        
        if json_match:
            json_str = json_match.group()
            actions = json.loads(json_str)
            return actions
        
        return None
    except Exception as e:
        print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

# ì•¡ì…˜ ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜ í•¨ìˆ˜
def simulate_action(action):
    """AIê°€ ì œì•ˆí•œ ì•¡ì…˜ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” í•¨ìˆ˜"""
    try:
        action_name = action.get('name', 'unknown')
        arguments = action.get('arguments', {})
        
        print(f"\nğŸ”§ ì•¡ì…˜ ì‹¤í–‰: {action_name}")
        
        if action_name == "open_left_window":
            percent = arguments.get('persent', 0)
            print(f"   ì™¼ìª½ ì°½ë¬¸ì„ {percent}% ì—´ì—ˆìŠµë‹ˆë‹¤.")
        elif action_name == "open_right_window":
            percent = arguments.get('persent', 0)
            print(f"   ì˜¤ë¥¸ìª½ ì°½ë¬¸ì„ {percent}% ì—´ì—ˆìŠµë‹ˆë‹¤.")
        elif action_name == "supply_water":
            liters = arguments.get('Liter', 0)
            print(f"   {liters}Lì˜ ë¬¼ì„ ê³µê¸‰í–ˆìŠµë‹ˆë‹¤.")
        elif action_name == "light_on":
            print(f"   ìƒì¥ë“±ì„ ì¼°ìŠµë‹ˆë‹¤.")
        elif action_name == "light_off":
            print(f"   ìƒì¥ë“±ì„ ê»ìŠµë‹ˆë‹¤.")
        else:
            print(f"   ì•Œ ìˆ˜ ì—†ëŠ” ì•¡ì…˜: {action_name}")
            
    except Exception as e:
        print(f"ì•¡ì…˜ ì‹¤í–‰ ì˜¤ë¥˜: {e}")

# ëŒ€í™”í˜• ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤
def chat():
    """ëŒ€í™”í˜• ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤"""
    print("\n" + "="*60)
    print("ğŸ  ìŠ¤ë§ˆíŠ¸í™ˆ AI ì±—ë´‡ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")
    print("="*60)
    print("\nì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹:")
    print("- 'quit', 'exit', 'ì¢…ë£Œ': ì±—ë´‡ ì¢…ë£Œ")
    print("- 'tools': ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ë³´ê¸°")
    print("- 'help': ë„ì›€ë§ ë³´ê¸°")
    print("\nì˜ˆì‹œ ì§ˆë¬¸:")
    print("- \"ì˜¨ë„ê°€ ë„ˆë¬´ ë†’ì•„ìš”\"")
    print("- \"ì‹ë¬¼ì—ê²Œ ë¬¼ì„ ì£¼ê³  ì‹¶ì–´ìš”\"")
    print("- \"ì¼ì¡°ëŸ‰ì´ ë¶€ì¡±í•´ìš”\"")
    print("="*60)
    
    while True:
        try:
            # ì‚¬ìš©ì ì…ë ¥
            user_input = input("\nğŸ  ì‚¬ìš©ì: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                print("\nï¿½ï¿½ ìŠ¤ë§ˆíŠ¸í™ˆ AI ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”!")
                break
            
            if user_input.lower() == 'tools':
                print("\nï¿½ï¿½ ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¤ë§ˆíŠ¸í™ˆ ë„êµ¬:")
                for tool in SMART_HOME_TOOLS:
                    print(f"  â€¢ {tool['name']}: {tool['description']}")
                continue
            
            if user_input.lower() == 'help':
                print("\nğŸ“– ë„ì›€ë§:")
                print("  â€¢ ìì—°ì–´ë¡œ ìŠ¤ë§ˆíŠ¸í™ˆ ì œì–´ ìš”ì²­ì„ ì…ë ¥í•˜ì„¸ìš”")
                print("  â€¢ AIê°€ ìƒí™©ì— ë§ëŠ” ì ì ˆí•œ ì•¡ì…˜ì„ ì œì•ˆí•©ë‹ˆë‹¤")
                print("  â€¢ 'tools' ëª…ë ¹ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
                continue
            
            if not user_input:
                continue
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (í›ˆë ¨ ë°ì´í„° í˜•ì‹ê³¼ ì¼ì¹˜)
            tools_json = json.dumps(SMART_HOME_TOOLS, ensure_ascii=False)
            prompt = f"Query: {user_input}\nTools: {tools_json}\nAnswer:"
            
            print("\nï¿½ï¿½ AIê°€ ì‘ë‹µì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
            
            # ì‘ë‹µ ìƒì„±
            response = generate_response(prompt)
            
            print(f"\nğŸ¤– AI: {response}")
            
            # JSON ì‘ë‹µ íŒŒì‹± ë° ì•¡ì…˜ ì‹¤í–‰
            actions = parse_json_response(response)
            if actions:
                print("\nğŸ“‹ ì œì•ˆëœ ì•¡ì…˜:")
                for action in actions:
                    simulate_action(action)
            
        except KeyboardInterrupt:
            print("\n\nï¿½ï¿½ ìŠ¤ë§ˆíŠ¸í™ˆ AI ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    chat()