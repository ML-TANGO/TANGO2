import json, traceback, time, sys, threading
import random
import logging
from collections import defaultdict
from functools import reduce
from typing import List
from enum import Enum

from confluent_kafka import Consumer
from confluent_kafka.admin import AdminClient, NewTopic
from kubernetes import config, client

from utils import TYPE, PATH, settings, topic_key, redis_key, common
from utils.msa_db import (
    db_project, db_workspace, db_deployment, db_node,
    db_instance, db_prepro, db_analyzing, db_collect
)
from utils.redis import get_redis_client, RedisQueue
from scheduler.collect_run import (
    create_crawling_collector, create_fb_deployment_collector,
    create_public_api_collector, create_remote_server_collector
)
from scheduler.project_tool_run import create_hps_pod, create_training_pod, create_project_tool
from scheduler.preprocessing_tool_run import create_preprocessing_tool, create_preprocessing_job
if settings.LLM_USED:
    from utils.llm_db import db_model
    from scheduler.llm_run import create_fine_tuning
    from scheduler.helm_run import uninstall_deployment_llm

from scheduler.helm_run import (
    install_deployment_pod, install_deployment_svc_ing, uninstall_pod_deployment,
    delete_helm_project, delete_helm_fine_tuning, install_deployment_llm,
    delete_helm_preprocessing, create_analyzer_pod, delete_helm_analyzer
)
from scheduler.resource_usage import *

config.load_kube_config(config_file=settings.KUBER_CONFIG_PATH)
coreV1Api = client.CoreV1Api()

KAFKA_TIMEOUT = 0.5
last_print_time = 0  
PRINT_INTERVAL = 3  # seconds

DEBUG = False
class Status(Enum):
    SUCCESS = 0
    FAIL_RETRY = 1  # ì‹¤íŒ¨ í›„ ì¬ì‹¤í–‰ ì‹œë„
    FAIL_PASS = 2   # ì‹¤íŒ¨ í›„ íŒ¨ìŠ¤

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')

"""
 ìì› ë¶€ì¡±:
   * pods "xxx" is forbidden: exceeded quota ...

 ì´ë¯¸ ì‹¤í–‰ì¤‘:
   Error: INSTALLATION FAILED: release: already exists
"""

# Consumer ì„¤ì •
conf = {
    'bootstrap.servers': settings.JF_KAFKA_DNS,
    'group.id': 'mygroup',
    'auto.offset.reset': 'earliest',
    'max.poll.interval.ms': 10000,
    'session.timeout.ms': 10000,
    'enable.auto.commit': True,
    'auto.commit.interval.ms': 5000,
}
kafka_admin_conf = {
    'bootstrap.servers': settings.JF_KAFKA_DNS
}

class ThreadingLock:
    def __init__(self, lock):
        self.lock = lock

    def __enter__(self):
        self.lock.acquire()

    def __exit__(self, t, v, tb):
        self.lock.release()
        if tb is not None:
            traceback.print_exception(t, v, tb)
        return True

jf_tlock = ThreadingLock(threading.Lock())


def create_topic(topics: List[str] = []):
    if not topics:
        return
    conf = {'bootstrap.servers': settings.JF_KAFKA_DNS}
    a = AdminClient(conf)
    new_topics = [topic for topic in topics if topic not in a.list_topics().topics]
    if new_topics:
        fs = a.create_topics([NewTopic(topic=topic, num_partitions=3, replication_factor=1) for topic in new_topics])
        for topic, f in fs.items():
            try:
                f.result()
                logging.info(f"âœ… Topic '{topic}' created successfully.")
            except Exception as e:
                logging.error(f"âŒ Failed to create topic '{topic}': {e}")
    else:
        logging.info("âœ… All topics are already created.")

def get_optimal_gpus(data: List[dict], num_gpus: int):
    """
    {
    "node-A": ["GPU1", "GPU2"],
    "node-B": ["GPU3"],
    ...
    } í˜•ì‹ìœ¼ë¡œ ì •ë¦¬ í›„ì— ê°€ìš© GPUê°€ ë§ì€ ë…¸ë“œë¶€í„° ìˆœì„œëŒ€ë¡œ í• ë‹¹

    """
    nodes = defaultdict(list)
    for item in data:
        nodes[item["node_name"]].append(item["gpu_uuid"])
    sorted_nodes = sorted(nodes.items(), key=lambda x: len(x[1]), reverse=True)

    result = []
    remaining_gpus = num_gpus

    for node, gpus in sorted_nodes:
        if remaining_gpus <= 0:
            break
        if len(gpus) >= remaining_gpus:
            result.extend([{"node_name": node, "gpu_uuid": gpu} for gpu in gpus[:remaining_gpus]])
            remaining_gpus = 0
        else:
            result.extend([{"node_name": node, "gpu_uuid": gpu} for gpu in gpus])
            remaining_gpus -= len(gpus)
    return result

# def get_optimal_gpus(available_gpus: List[dict], num_gpus: int):
#     """
#     ê°€ëŠ¥í•œ í•œ ì ì€ ë…¸ë“œì—ì„œ ë§ì€ GPUë¥¼ í• ë‹¹í•˜ë„ë¡ ê°œì„ í•œ ë¡œì§.
#     ë™ì¼ ì¡°ê±´ì—ì„œëŠ” ë¬´ì‘ìœ„ë¡œ ë…¸ë“œë¥¼ ì„ íƒí•¨.
#     """
#     print("### avail:", available_gpus)
#     # ìš°ì„  gpu_countë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
#     sorted_nodes = sorted(available_gpus, key=lambda x: x["gpu_count"], reverse=True)

#     # ë™ì¼í•œ gpu_countë¥¼ ê°€ì§„ ë…¸ë“œë¥¼ ê·¸ë£¹í•‘í•˜ì—¬ ì…”í”Œ
#     gpu_count_groups = {}
#     for node in sorted_nodes:
#         gpu_count = node["gpu_count"]
#         gpu_count_groups.setdefault(gpu_count, []).append(node)

#     # ê° ê·¸ë£¹ ë‚´ì—ì„œ ë…¸ë“œë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ìŒ
#     randomized_nodes = []
#     for gpu_count in sorted(gpu_count_groups.keys(), reverse=True):
#         nodes = gpu_count_groups[gpu_count]
#         random.shuffle(nodes)
#         randomized_nodes.extend(nodes)

#     # GPU í• ë‹¹ ìˆ˜í–‰
#     result = []
#     remaining_gpus = num_gpus

#     for node_info in randomized_nodes:
#         if remaining_gpus <= 0:
#             break

#         allocatable = min(node_info["gpu_count"], remaining_gpus)
#         result.append({
#             "node_name": node_info["node_name"],
#             "allocated_gpu_count": allocatable
#         })
#         remaining_gpus -= allocatable

#     if remaining_gpus > 0:
#         raise ValueError("ìš”ì²­í•œ GPU ê°œìˆ˜ë³´ë‹¤ ì‚¬ìš© ê°€ëŠ¥í•œ GPUê°€ ì ìŠµë‹ˆë‹¤.")

#     return result

def gpu_auto_clustering(available_gpus: List[dict], pod_per_gpu: int = None):
    grouped_data = defaultdict(list)
    for item in available_gpus:
        grouped_data[item["node_name"]].append(item["gpu_uuid"])

    def gcd(a, b):
        while b:
            a, b = b, a % b
        return a

    def gcd_multiple(numbers):
        return reduce(gcd, numbers)

    node_counts = {node: len(uuids) for node, uuids in grouped_data.items()}
    counts = list(node_counts.values())

    if pod_per_gpu:
        max_gcd = pod_per_gpu
    else:
        max_gcd = gcd_multiple(counts)

    result = []
    for node, uuids in grouped_data.items():
        chunks = [uuids[i:i + max_gcd] for i in range(0, len(uuids), max_gcd)]
        for chunk in chunks:
            result.append({"node_name": node, "gpu_uuids": chunk})
    return result
# def gpu_auto_clustering(optimal_allocations: List[dict], pod_per_gpu: int = 1):
#     """
#     ê° ë…¸ë“œì˜ GPU ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ pod_per_gpuë¡œ ë‚˜ëˆ„ì–´ í´ëŸ¬ìŠ¤í„°ë§.
#     """
#     clusters = []
#     for alloc in optimal_allocations:
#         node_name = alloc["node_name"]
#         gpu_count = alloc["allocated_gpu_count"]

#         full_clusters, remainder = divmod(gpu_count, pod_per_gpu)

#         # í’€ í´ëŸ¬ìŠ¤í„° ë°°ì •
#         for _ in range(full_clusters):
#             clusters.append({
#                 "node_name": node_name,
#                 "gpu_count": pod_per_gpu
#             })

#         # ë‚˜ë¨¸ì§€ GPUê°€ ìˆìœ¼ë©´ ë³„ë„ í´ëŸ¬ìŠ¤í„°ë¡œ ë°°ì •
#         if remainder:
#             clusters.append({
#                 "node_name": node_name,
#                 "gpu_count": remainder
#             })

#     return clusters

def get_used_gpu_uuid(label_select: str):
    used_gpu_uuid = []
    live_pods = coreV1Api.list_pod_for_all_namespaces(label_selector=label_select).items
    for live_pod in live_pods:
        pod_labels = live_pod.metadata.labels
        pod_status = live_pod.status.phase
        if pod_status not in ["Succeeded", "Failed"]:
            if "gpu_ids" in pod_labels:
                for gpu_id in pod_labels["gpu_ids"].split("."):
                    if gpu_id:
                        used_gpu_uuid.append(db_node.get_node_gpu(gpu_id=gpu_id)["gpu_uuid"])
    return list(set(used_gpu_uuid))

def get_available_gpus_by_model(model_name, data, instance_id):
    node_list = db_node.get_node_instance_list(instance_id=instance_id)
    node_name_list = [node["node_name"] for node in node_list]

    available_gpus = [
        {"node_name": node_name, "gpu_uuid": gpu_uuid}
        for node_name, gpus in data.items()
        for gpu_uuid, gpu in gpus.items()
        if gpu['model_name'] == model_name and not gpu['used_info'] and node_name in node_name_list
    ]
    return available_gpus

def acked(err, msg):
    if err is not None:
        print("Failed to deliver message: %s: %s" % (str(msg), str(err)))
    else:
        print("Message produced: %s" % (str(msg)))

def try_json_deserializer(data):
    try:
        return json.loads(data.decode('utf-8'))
    except (json.JSONDecodeError, AttributeError):
        print("ë””ì½”ë“œ ì˜¤ë¥˜", file=sys.stderr)
        return json.loads(data)

def get_gpu_auto_select(gpu_count: int, pod_count: int, gpu_data: list):
    # ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    result = []

    # GPUë¥¼ ë…¸ë“œ ì´ë¦„ë³„ë¡œ ê·¸ë£¹í™”
    available_gpus = {}
    for gpu_info in gpu_data:
        node_name = gpu_info['node_name']
        gpu_uuid = gpu_info['gpu_uuid']
        if node_name not in available_gpus:
            available_gpus[node_name] = []
        available_gpus[node_name].append(gpu_uuid)

    # í•„ìš”í•œ GPUì˜ ì´ ìˆ˜
    total_required_gpus = pod_count * gpu_count

    # ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” GPUë¥¼ í• ë‹¹
    allocated_gpus = 0
    for node_name, gpus in available_gpus.items():
        if len(gpus) < gpu_count: # í•´ë‹¹ ë…¸ë“œì— podì— ê°™ì´ í• ë‹¹ í•  ìˆ˜ ìˆëŠ” gpu ê°œìˆ˜ê°€ ë¶€ì¡±í•  ê²½ìš° pass
            continue
        while allocated_gpus < total_required_gpus and gpus:
            for _ in range(gpu_count):
                if gpus and allocated_gpus < total_required_gpus:
                    result.append({'node_name': node_name, 'gpu_uuid': gpus.pop(0)})
                    allocated_gpus += 1

        # í•„ìš”í•œ GPUì˜ ìˆ˜ì— ë„ë‹¬í•˜ë©´ ë£¨í”„ ì¢…ë£Œ
        if allocated_gpus >= total_required_gpus:
            break

    # í•„ìš”í•œ GPUê°€ ì¶©ë¶„í•˜ì§€ ì•Šì€ ê²½ìš° ì˜ˆì™¸ ë°œìƒ
    if allocated_gpus < total_required_gpus:
        return []

    return result


# --------------------------------------------------------------------------------
# (A) Kafka ë©”ì‹œì§€ -> Pending Pod íì— ì €ì¥
# --------------------------------------------------------------------------------
def run_kafka_consumer():
    """
    Kafkaì—ì„œ pod_info ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ í•˜ì—¬,
    ë©”ì‹œì§€ì— í¬í•¨ëœ workspace_id ê¸°ì¤€ìœ¼ë¡œ 'WORKSPACE_ITEM_PENDING_POD2'ì— ì €ì¥.
    (ì‹¤ì œ ì‹¤í–‰ì€ run_scheduler()ì—ì„œ ì²˜ë¦¬)
    """
    logging.info("Starting Kafka Consumer...")
    consumer = Consumer(conf)
    kafka_admin = AdminClient(kafka_admin_conf)
    
    type_id_map = {
                TYPE.PROJECT_TYPE: "project_id",
                TYPE.DEPLOYMENT_TYPE: "deployment_id",
                TYPE.PREPROCESSING_TYPE: "preprocessing_id",
                TYPE.ANALYZER_TYPE: "analyzer_id",
                TYPE.COLLECT_TYPE: "collect_id",
                TYPE.FINE_TUNING_TYPE: "model_id" if settings.LLM_USED else None
            }

    while True:
        try:
            time.sleep(0.3)

            # TODO: ì¶”í›„ í† í”½ êµ¬ì¡° ë³€ê²½
            pod_info = dict()
            kafka_topic_list = [topic for topic in kafka_admin.list_topics().topics]
            kafka_topic_list = [x for x in kafka_topic_list if x != '__consumer_offsets']
            if not kafka_topic_list:
                continue
            consumer.subscribe(kafka_topic_list)

            try:
                msgs = consumer.consume(num_messages=100, timeout=KAFKA_TIMEOUT)  # ì‹ ê·œ ë©”ì‹œì§€ ì—†ì„ ì‹œ None ë°˜í™˜
                if not msgs:
                    continue
            except Exception as e:
                logging.error("Exception occurred while fetching Kafka message", exc_info=True)
                continue
            
            redis_client = get_redis_client()
            for msg in msgs:
                pod_info = try_json_deserializer(msg.value())
                logging.info(f"[kafka polled msg] pod_info: {json.dumps(pod_info, ensure_ascii=False)}")
                # ë©”ì‹œì§€ì—ì„œ workspace_id ì¶”ì¶œ
                ws_id = pod_info.get("workspace_id") or pod_info.get("metadata_workspace_id")
                if not ws_id:
                    logging.info("No workspace_id in pod_info, skipping.")
                    continue
                # {item_type}:{workspace_id}
                # Pending Pod íì— ì €ì¥
                raw_pending = redis_client.hget(redis_key.WORKSPACE_ITEM_PENDING_POD2, ws_id)
                if not raw_pending:
                    workspace_item_pending_pod = {
                        TYPE.PROJECT_TYPE: {},
                        TYPE.DEPLOYMENT_TYPE: {},
                        TYPE.PREPROCESSING_TYPE: {},
                        TYPE.ANALYZER_TYPE: {},
                        TYPE.COLLECT_TYPE: {},
                        TYPE.FINE_TUNING_TYPE: {}
                    }
                else:
                    workspace_item_pending_pod = json.loads(raw_pending)

                # pod_typeë³„ë¡œ ë¶„ë¥˜
                ptype = pod_info["pod_type"]

                # pod_infoì—ì„œ í•´ë‹¹ íƒ€ì…ë³„ ID ê°€ì ¸ì˜¤ê¸°
                item_key = type_id_map.get(ptype)
                if item_key:
                    item_id = pod_info.get(item_key)
                    if item_id:
                        # ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€: ë™ì¼í•œ pod_infoê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
                        existing_items = workspace_item_pending_pod.setdefault(ptype, {}).setdefault(str(item_id), [])
                        # pod_infoì˜ ê³ ìœ  ì‹ë³„ìë¡œ ì¤‘ë³µ ì²´í¬ (id ê¸°ì¤€)
                        if not any(existing['id'] == pod_info['id'] for existing in existing_items):
                            existing_items.append(pod_info)
                            logging.info(f"[NEW POD ADDED] {ptype} ID {item_id}: pod_info added to pending")
                        else:
                            logging.info(f"[DUPLICATE SKIPPED] {ptype} ID {item_id}: pod_info already exists in pending")
                logging.info(f"[workspace_item_pending_pod] : {json.dumps(workspace_item_pending_pod, ensure_ascii=False)}")
                # Redisì— ë‹¤ì‹œ ì €ì¥
                redis_client.hset(redis_key.WORKSPACE_ITEM_PENDING_POD2, ws_id, json.dumps(workspace_item_pending_pod))

        except Exception as e:
            consumer.unsubscribe()
            traceback.format_exc()
            time.sleep(1)
    # consumer.close() # í•„ìš”ì‹œ

def kafka_consume_msgs(consumer, kafka_admin, redis_client, type_id_map):
    """
    Kafkaì—ì„œ pod_info ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ í•˜ì—¬,
    ë©”ì‹œì§€ì— í¬í•¨ëœ workspace_id ê¸°ì¤€ìœ¼ë¡œ 'WORKSPACE_ITEM_PENDING_POD2'ì— ì €ì¥.
    """
    try:

        # TODO: ì¶”í›„ í† í”½ êµ¬ì¡° ë³€ê²½
        pod_info = dict()
        # kafka_topic_list = [topic for topic in kafka_admin.list_topics().topics if topic != '__consumer_offsets']
        # if not kafka_topic_list:
        #     return
        consumer.subscribe([str(topic_key.SCHEDULER_TOPIC)])

        try:
            msgs = consumer.consume(num_messages=100, timeout=KAFKA_TIMEOUT)  # ì‹ ê·œ ë©”ì‹œì§€ ì—†ì„ ì‹œ None ë°˜í™˜
            if not msgs:
                return True
        except Exception as e:
            logging.error("Exception occurred while fetching Kafka message", exc_info=True)
            return True
        
        for msg in msgs:
            pod_info = try_json_deserializer(msg.value())
            logging.info(f"[kafka polled msg] pod_info: {json.dumps(pod_info, ensure_ascii=False)}")
            # ë©”ì‹œì§€ì—ì„œ workspace_id ì¶”ì¶œ
            ws_id = pod_info.get("workspace_id") or pod_info.get("metadata_workspace_id")
            if not ws_id:
                logging.info("No workspace_id in pod_info, skipping.")
                continue
            # {item_type}:{workspace_id}
            # Pending Pod íì— ì €ì¥
            raw_pending = redis_client.hget(redis_key.WORKSPACE_ITEM_PENDING_POD2, ws_id)
            if not raw_pending:
                workspace_item_pending_pod = {
                    TYPE.PROJECT_TYPE: {
                        # "1" : []
                    },
                    TYPE.DEPLOYMENT_TYPE: {},
                    TYPE.PREPROCESSING_TYPE: {},
                    TYPE.ANALYZER_TYPE: {},
                    TYPE.COLLECT_TYPE: {},
                    TYPE.FINE_TUNING_TYPE: {}
                }
            else:
                workspace_item_pending_pod = json.loads(raw_pending)

            # pod_typeë³„ë¡œ ë¶„ë¥˜
            ptype = pod_info.get("pod_type", None)
            if not ptype:
                continue
            # pod_infoì—ì„œ í•´ë‹¹ íƒ€ì…ë³„ ID ê°€ì ¸ì˜¤ê¸°
            item_key = type_id_map.get(ptype)
            if item_key:
                item_id = pod_info.get(item_key)
                if item_id:
                    # ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€: ë™ì¼í•œ pod_infoê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
                    existing_items = workspace_item_pending_pod.setdefault(ptype, {}).setdefault(str(item_id), [])
                    # pod_infoì˜ ê³ ìœ  ì‹ë³„ìë¡œ ì¤‘ë³µ ì²´í¬ (id ê¸°ì¤€)
                    if not any(existing['id'] == pod_info['id'] for existing in existing_items):
                        existing_items.append(pod_info)
                        logging.info(f"[NEW POD ADDED] {ptype} ID {item_id}: pod_info added to pending")
                    else:
                        logging.info(f"[DUPLICATE SKIPPED] {ptype} ID {item_id}: pod_info already exists in pending")
            logging.info(f"[workspace_item_pending_pod] : {json.dumps(workspace_item_pending_pod, ensure_ascii=False)}")
            # Redisì— ë‹¤ì‹œ ì €ì¥
            redis_client.hset(redis_key.WORKSPACE_ITEM_PENDING_POD2, ws_id, json.dumps(workspace_item_pending_pod))

        # ë©”ì‹œì§€ ì²˜ë¦¬ ì™„ë£Œ í›„ commit
        try:
            consumer.commit()
        except Exception as e:
            logging.error(f"Failed to commit offset: {e}")

    except Exception as e:
        traceback.print_exc()
        try:
            consumer.unsubscribe()
        except:
            pass
        try:
            consumer.close()
        except:
            pass
        logging.error("Kafka consumer error, will reinitialize", exc_info=True)
        return False  # ì‹¤íŒ¨ ì²˜ë¦¬


# --------------------------------------------------------------------------------
# (B) Workspace ìŠ¤ì¼€ì¤„ëŸ¬ (ê¸°ì¡´ pod_start_new() ë¡œì§)
# --------------------------------------------------------------------------------
def run_scheduler():
    """
    1) ëª¨ë“  workspaceë¥¼ ìˆœíšŒí•˜ë©°,
       - Pending Podì—ì„œ ìì› ì‚¬ìš©ëŸ‰ ê³„ì‚° í›„, ì‹¤í–‰ ê°€ëŠ¥í•˜ë©´ ì¸ìŠ¤í„´ìŠ¤ íë¡œ ì´ë™
       - ì¸ìŠ¤í„´ìŠ¤ íì—ì„œ pop -> Helm ë°°í¬ -> ì‹¤íŒ¨ ì‹œ ë¡¤ë°±/ì¬ëŒ€ê¸°
    2) ê¸°ì¡´ì˜ pod_start_new() í•¨ìˆ˜ë¥¼ ëŒ€ì²´
    """

    def db_sync(pod_info: dict, project=None, deployment=None, preprocessing=None, analyzer=None, fine_tuning=None, collect=None):
        if pod_info["pod_type"] == TYPE.PROJECT_TYPE:
            if pod_info["work_func_type"] == TYPE.TRAINING_ITEM_A:
                training_info = db_project.get_training(training_id=pod_info["id"])
                if training_info is None or training_info["end_datetime"]:
                    return False
            elif pod_info["work_func_type"] == TYPE.TRAINING_ITEM_C:
                hps_info = db_project.get_hps(hps_id=pod_info["id"])
                if hps_info is None or hps_info["end_datetime"]:
                    return False
            elif pod_info["work_func_type"] == TYPE.TRAINING_ITEM_B:
                tool_info = db_project.get_project_tool(project_tool_id=pod_info["id"])
                if tool_info is None or not tool_info['request_status'] or tool_info["end_datetime"]:
                    return False
        elif pod_info["pod_type"] == TYPE.PREPROCESSING_TYPE:
            if pod_info["work_func_type"] == TYPE.PREPROCESSING_ITEM_A:
                tool_info = db_prepro.get_preprocessing_tool_sync(preprocessing_tool_id=pod_info["id"])
                if tool_info is None or not tool_info['request_status']:
                    return False
            elif pod_info["work_func_type"] == TYPE.PREPROCESSING_ITEM_B:
                job_info = db_prepro.get_job_simple(preprocessing_job_id=pod_info["id"])
                if job_info is None or job_info["end_datetime"]:
                    return False
        elif pod_info["pod_type"] == TYPE.ANALYZER_TYPE:
            analyzer_graph_info = db_analyzing.get_analyzer_graph_sync(id=pod_info.get("graph_id"))
            if analyzer_graph_info is None or analyzer_graph_info.get("end_datetime"):
                return False
        elif pod_info["pod_type"] == TYPE.DEPLOYMENT_TYPE: # ë°°í¬
            worker_info = db_deployment.get_deployment_worker(deployment_worker_id=pod_info["deployment_worker_id"])
            if worker_info is None or worker_info["end_datetime"]:
                return False
        elif pod_info["pod_type"] == TYPE.FINE_TUNING_TYPE:
            model_info = db_model.get_model_sync(model_id=pod_info["model_id"])
            if model_info is None or \
                model_info["latest_fine_tuning_status"] in \
                        [TYPE.KUBE_POD_STATUS_STOP, TYPE.KUBE_POD_STATUS_ERROR, TYPE.KUBE_POD_STATUS_RUNNING, TYPE.KUBE_POD_STATUS_DONE]:
                return False
        elif pod_info["pod_type"] == TYPE.COLLECT_TYPE:
            collect_info = db_collect.get_collect_info(collect_id=pod_info["collect_info"]["id"])
            if collect_info is None or collect_info["end_datetime"]:
                return False
        return True

    def workspace_db_sync(pod_info):
        pt = pod_info.get("pod_type")
        if pt == TYPE.PROJECT_TYPE:
            wft = pod_info.get("work_func_type")
            if wft == TYPE.TRAINING_ITEM_A:
                training_info = db_project.get_training(training_id=pod_info["id"])
                if (training_info is None or
                    training_info["end_status"] == TYPE.KUBE_POD_STATUS_STOP or
                    training_info["instance_id"] is None or
                    training_info["end_datetime"]):
                    return False
            elif wft == TYPE.TRAINING_ITEM_C:
                hps_info = db_project.get_hps(hps_id=pod_info["id"])
                if hps_info is None or hps_info["end_datetime"]:
                    return False
            elif wft == TYPE.TRAINING_ITEM_B:
                tool_info = db_project.get_project_tool(project_tool_id=pod_info["id"])
                if (tool_info is None or
                    not tool_info['request_status'] or
                    tool_info["gpu_count"] != pod_info["gpu_count"] or
                    tool_info["image_real_name"] != pod_info["image_name"] or
                    json.loads(tool_info["gpu_select"]) != pod_info["gpu_select"] or
                    tool_info["instance_id"] is None or
                    tool_info["end_datetime"]):
                    return False
        elif pt == TYPE.PREPROCESSING_TYPE:
            wft = pod_info.get("work_func_type")
            if wft == TYPE.PREPROCESSING_ITEM_A:
                tool_info = db_prepro.get_preprocessing_tool_sync(preprocessing_tool_id=pod_info["id"])
                if (tool_info is None or
                    not tool_info['request_status'] or
                    tool_info["gpu_count"] != pod_info["gpu_count"] or
                    tool_info["image_real_name"] != pod_info["image_name"] or
                    json.loads(tool_info["gpu_select"]) != pod_info["gpu_select"] or
                    tool_info["instance_id"] is None or
                    tool_info["end_datetime"]):
                    return False
            elif wft == TYPE.PREPROCESSING_ITEM_B:
                job_info = db_prepro.get_job_simple(preprocessing_job_id=pod_info["id"])
                if (job_info is None or job_info["end_datetime"] or job_info["instance_id"] is None):
                    return False
        elif pt == TYPE.ANALYZER_TYPE:
            analyzer_graph_info = db_analyzing.get_analyzer_graph_sync(id=pod_info.get("graph_id"))
            if (analyzer_graph_info is None or
                analyzer_graph_info.get("end_datetime") or
                analyzer_graph_info.get("instance_id") is None):
                return False
        elif pt == TYPE.DEPLOYMENT_TYPE:
            worker_info = db_deployment.get_deployment_worker(deployment_worker_id=pod_info["deployment_worker_id"])
            if (worker_info is None or
                worker_info["end_datetime"] or
                worker_info["instance_id"] is None):
                return False
        elif pt == TYPE.COLLECT_TYPE:
            collect_info = db_collect.get_collect_info(collect_id=pod_info["collect_info"]["id"])
            if (collect_info is None or
                collect_info["end_datetime"] or
                collect_info["instance_id"] is None):
                return False
        if settings.LLM_USED:
            if pt == TYPE.FINE_TUNING_TYPE:
                model_info = db_model.get_model_sync(model_id=pod_info["model_id"])
                if model_info is None or \
                    model_info["latest_fine_tuning_status"] in \
                        [TYPE.KUBE_POD_STATUS_STOP, TYPE.KUBE_POD_STATUS_ERROR, TYPE.KUBE_POD_STATUS_RUNNING, TYPE.KUBE_POD_STATUS_DONE]:
                    return False
        return True

    

    def calculate_pending_in_instance_queue(redis_queue, item, item_type):
        """
        ì¸ìŠ¤í„´ìŠ¤ íì— ë“¤ì–´ìˆëŠ” pod_infoë“¤ ì¤‘,
        item_type/idê°€ ë™ì¼í•œ ê²ƒë“¤ì„ ëª¨ì•„ì„œ pending cpu/ram/gpuë¥¼ í•©ì‚°
        """
        def is_same_item(qpod, item_type, item_id):
            """
            qpod ì•ˆì— ìˆëŠ” id(project_id, deployment_id ë“±)ì™€
            í˜„ì¬ item['id']ê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
            """
            if item_type == TYPE.PROJECT_TYPE:
                return qpod.get("project_id") == item_id
            elif item_type == TYPE.DEPLOYMENT_TYPE:
                return qpod.get("deployment_id") == item_id
            elif item_type == TYPE.PREPROCESSING_TYPE:
                return qpod.get("preprocessing_id") == item_id
            elif item_type == TYPE.ANALYZER_TYPE:
                return qpod.get("analyzer_id") == item_id
            elif item_type == TYPE.COLLECT_TYPE:
                return qpod.get("collect_id") == item_id
            return False
        
        USAGE_CALC_MAP = {
            TYPE.PROJECT_TYPE: usage_for_project,
            TYPE.DEPLOYMENT_TYPE: usage_for_deployment,
            TYPE.PREPROCESSING_TYPE: usage_for_preprocessing,
            TYPE.ANALYZER_TYPE: usage_for_analyzer,
            TYPE.COLLECT_TYPE: usage_for_collector,
            TYPE.FINE_TUNING_TYPE: usage_for_fine_tuning,
            # LLM ë“± ë‹¤ë¥¸ í•­ëª©ì´ í•„ìš”í•˜ë‹¤ë©´ ì¶”ê°€
        }

        pending_cpu = 0
        pending_ram = 0
        pending_gpu = 0

        calc_fn = USAGE_CALC_MAP.get(item_type, None)
        if not calc_fn:
            # item_typeì— ëŒ€ì‘í•˜ëŠ” usage í•¨ìˆ˜ê°€ ì—†ìœ¼ë©´ ë°”ë¡œ ë°˜í™˜
            return 0, 0, 0

        instance_items = redis_queue.fetch_queue_items()
        for data in instance_items:
            qpod = json.loads(data)

            # 1) item_type/id ë§¤ì¹­ ì—¬ë¶€ í™•ì¸
            if not is_same_item(qpod, item_type, item["id"]):
                # í•­ëª©ì´ ë‹¬ë¼ì„œ ìŠ¤í‚µ
                continue

            # 2) GPU ê°œìˆ˜ ë° pod_count ê³„ì‚°
            p_gpu = qpod["gpu_count"]
            pod_count = 1
            if qpod["gpu_cluster_auto"] and qpod["gpu_auto_cluster_case"]:
                pod_count = qpod["gpu_auto_cluster_case"]["server"]
            elif p_gpu > 1 and qpod["pod_per_gpu"]:
                pod_count = p_gpu / qpod["pod_per_gpu"]

            # 3) CPU, RAM ê³„ì‚° (í•­ëª©ë³„ ì „ë‹´ í•¨ìˆ˜ í™œìš©)
            cpu, ram = calc_fn(item, qpod, pod_count)

            # 4) pending ëˆ„ì 
            pending_cpu += cpu
            pending_ram += ram
            pending_gpu += p_gpu

        return pending_cpu, pending_ram, pending_gpu



    def process_item_type(
        ws_id,
        workspace_item_pending_pod,
        workspace_instance_used_resource,
        item_type,
        get_item_list_fn,
        calculate_usage_fn,
        get_limits_fn,
        db_sync_fn
    ):
        """
        1) DBì—ì„œ item_listë¥¼ ê°€ì ¸ì˜´
        2) ìì› ì‚¬ìš©ëŸ‰ì„ í•©ì‚° â†’ workspace_instance_used_resource
        3) pending_pod í™•ì¸ + db_sync
        4) ì¸ìŠ¤í„´ìŠ¤ íì—ì„œ ì´ë¯¸ ëŒ€ê¸°ì¤‘ì¸ podë“¤ì˜ ìì›(pending) ê³„ì‚°
        5) available vs required ë¹„êµ â†’ ì¸ìŠ¤í„´ìŠ¤ íë¡œ rput or pending ìœ ì§€
        """
        redis_client = get_redis_client()
        pending_dict = workspace_item_pending_pod.get(item_type, {})

        item_list = get_item_list_fn(workspace_id=ws_id)

        # ì‚­ì œëœ item id ì‚­ì œ ìš©ìœ¼ë¡œ ì¶”ê°€
        # í•´ë‹¹ ë¡œì§ì´ ì—†ì–´ë„ ê¸°ëŠ¥ìƒ ë¬¸ì œëŠ” ì—†ìŒ(ì‚­ì œí•´ë„ ë¬´ë°©)
        #=========
        item_str_id_list = [str(item["id"]) for item in item_list]
        pending_str_id_list = list(pending_dict.keys())
        del_item_ids = set(pending_str_id_list) - set(item_str_id_list) 
        for del_item_id in list(del_item_ids):
            del pending_dict[del_item_id]
        #=========

        for item in item_list:
            # 1) ìì› ì‚¬ìš©ëŸ‰ ê³„ì‚°
            used_cpu, used_ram, used_gpu = calculate_usage_fn(item)

            inst_id = item["instance_id"]
            # ì¸ìŠ¤í„´ìŠ¤ í
            inst_queue_key = redis_key.WORKSPACE_INSTANCE_QUEUE.format(ws_id, inst_id)
            redis_queue = RedisQueue(redis_client=redis_client, key=inst_queue_key)
            if inst_id not in workspace_instance_used_resource:
                workspace_instance_used_resource[inst_id] = {"cpu":0, "ram":0, "gpu":0}
            workspace_instance_used_resource[inst_id]["cpu"] += used_cpu
            workspace_instance_used_resource[inst_id]["ram"] += used_ram
            workspace_instance_used_resource[inst_id]["gpu"] += used_gpu
            # 2) Pending Pod ìˆëŠ”ì§€ í™•ì¸
            item_id_str = str(item["id"])
            if item_id_str in pending_dict and pending_dict[item_id_str] != []:
                pod_info = pending_dict[item_id_str].pop(0)
            else:
                # ë§Œì•½ pod_infoì˜ item_idê°€ item["id"]ì¸ì§€ ì²´í¬
                # ì—†ìœ¼ë©´ continue
                continue

            # DB sync
            if not db_sync_fn(
                pod_info=pod_info,
                **{item_type: item}  # ex) project=project
            ):
                logging.info(f"[PENDING REMOVED] {pod_info['pod_type']} ID {item_id_str}: ì‚¬ìš©ì ì¤‘ì§€, ì‚­ì œ")
                continue

            pen_cpu, pen_ram, pen_gpu = calculate_pending_in_instance_queue(redis_queue, item, item_type)
            # pen_cpu, pen_ram, pen_gpu = 0, 0, 0

            # total
            total_cpu = item["cpu_allocate"] * item["instance_allocate"]
            total_ram = item["ram_allocate"] * item["instance_allocate"]
            total_gpu = item["gpu_allocate"] * item["instance_allocate"]


            available_cpu = total_cpu - used_cpu - pen_cpu
            available_ram = total_ram - used_ram - pen_ram
            available_gpu = total_gpu - used_gpu - pen_gpu

            # CPU/RAM Limit
            limit_cpu, limit_ram = get_limits_fn(item, pod_info)
            # GPU count
            gpu_count = pod_info["gpu_count"]

            # pod_count ê³„ì‚° (gpu_cluster_auto ë“±, ì›ë³¸ ë¡œì§ ê·¸ëŒ€ë¡œ)
            pod_count = 1
            # print("pod_info:", pod_info)
            pod_per_gpu = pod_info["pod_per_gpu"] if pod_info.get("pod_per_gpu") else 1
            if pod_info["gpu_cluster_auto"] and pod_info["gpu_auto_cluster_case"]:
                pod_count = pod_info["gpu_auto_cluster_case"]["server"]
                pod_per_gpu = pod_info["gpu_auto_cluster_case"]["gpu_count"]
                pod_info["pod_per_gpu"] = pod_per_gpu
            elif gpu_count > 1 and pod_per_gpu:
                pod_count = gpu_count / pod_per_gpu
            pod_info["pod_count"] = pod_count


            # ìì› ë¹„êµ
            # TODO
            # íŒŒì¸íŠœë‹ì˜ ê²½ìš° get_limits_fn ì—¬ê¸°ì„œ ì´ë¯¸ ê³„ì‚°ë¨
            # ë”°ë¼ì„œ, pod_count ë¥¼ ê³±í•˜ë©´ ì•ˆë¨
            if item_type == TYPE.FINE_TUNING_TYPE:
                need_cpu = limit_cpu
                need_ram = limit_ram
                need_gpu = gpu_count
                pod_info["resource"] = {"cpu": limit_cpu, "ram": limit_ram}
            else:
                need_cpu = limit_cpu * pod_count * (pod_per_gpu if pod_per_gpu > 1 else 1)
                need_ram = limit_ram * pod_count * (pod_per_gpu if pod_per_gpu > 1 else 1)
                need_gpu = gpu_count
                pod_info["resource"] = {"cpu": limit_cpu * (pod_per_gpu if pod_per_gpu > 1 else 1), "ram": limit_ram * (pod_per_gpu if pod_per_gpu > 1 else 1)}

            
            
            if (available_cpu < need_cpu) or (available_ram < need_ram) or (available_gpu < need_gpu):
                logging.info(
                    f"{pod_info['pod_type']} ID {item_id_str}: ìì› ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ Pending - CPU/RAM/GPU Available: {available_cpu}/{available_ram}/{available_gpu} | Need: {need_cpu}/{need_ram}/{need_gpu}"
                )
                pending_dict[item_id_str].insert(0, pod_info)  # ìì›ì´ ë¶€ì¡±í•˜ì—¬ pending ìƒíƒœë¡œ ìœ ì§€
            else:
                # ìì› ì¶©ë¶„ â†’ pending ì œê±°, ì¸ìŠ¤í„´ìŠ¤ í
                if item_id_str in pending_dict:
                    # del pending_dict[item_id_str]
                    logging.info(f"[PENDING REMOVED] {pod_info['pod_type']} ID {item_id_str}: ìì› í™•ë³´ ì™„ë£Œ â†’ ëŒ€ê¸° í•´ì œ")
                 
                try:
                    
                    redis_queue.rput(json.dumps(pod_info))                  
                    logging.info(
                        f"[QUEUE SUCCESS] {pod_info['pod_type']} ID {item_id_str}: ì¸ìŠ¤í„´ìŠ¤ íì— ì¶”ê°€ ì™„ë£Œ (CPU: {need_cpu}, RAM: {need_ram}, GPU: {need_gpu})"
                    )
                except Exception as e:
                    logging.error(f"[QUEUE ERROR] {pod_info['pod_type']} ID {item_id_str}: í ì¶”ê°€ ì‹¤íŒ¨ - {e}")

        if DEBUG:
            logging.info("[WORKSPACE ITEM USED RESOURCE] : [%s] : %s", item_type ,json.dumps(workspace_instance_used_resource, ensure_ascii=False))

    ITEM_PROCESSORS = {
    TYPE.PROJECT_TYPE: {
        "get_item_list_fn": db_project.get_project_list,        # (workspace_id=...)
        "calculate_usage_fn": calculate_project_usage,
        "get_limits_fn": get_project_limits,
        "db_sync_fn": db_sync,  # ì›ë³¸ db_sync í•¨ìˆ˜
    },
    TYPE.DEPLOYMENT_TYPE: {
        "get_item_list_fn": db_deployment.get_deployment_list_in_workspace,
        "calculate_usage_fn": calculate_deployment_usage,
        "get_limits_fn": get_deployment_limits,
        "db_sync_fn": db_sync,
    },
    TYPE.PREPROCESSING_TYPE: {
        "get_item_list_fn": db_prepro.get_preprocessing_list_sync,
        "calculate_usage_fn": calculate_preprocessing_usage,
        "get_limits_fn": get_preprocessing_limits,
        "db_sync_fn": db_sync,
    },
    TYPE.ANALYZER_TYPE: {
        "get_item_list_fn": db_analyzing.get_analyzer_list,
        "calculate_usage_fn": calculate_analyzer_usage,
        "get_limits_fn": get_analyzer_limits,
        "db_sync_fn": db_sync,
    },
    TYPE.COLLECT_TYPE: {
        "get_item_list_fn": db_collect.get_collect_list,
        "calculate_usage_fn": calculate_collector_usage,
        "get_limits_fn": get_collector_limits,
        "db_sync_fn": db_sync,
    },
    TYPE.FINE_TUNING_TYPE: {
        "get_item_list_fn": db_model.get_models_sync,
        "calculate_usage_fn": calculate_fine_tuning_usage,
        "get_limits_fn": get_fine_tuning_limits,
        "db_sync_fn": db_sync,                               # TODO: Fine Tuningì€ ì‹¤ì œë¡  db_sync í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•„ ë¬¸ì œ ìƒê¸¸ ì—¬ì§€ ìˆìœ¼ë¯€ë¡œ í™•ì¸ í•„ìš”
    },
    }

    def process_all_item_types(ws_id, workspace_item_pending_pod, workspace_instance_used_resource):
        """
        Project / Deployment / Preprocessing / Analyzer / Collector ë“±
        ëª¨ë“  í•­ëª©ì— ëŒ€í•´ process_item_type(...)ë¥¼ í•œêº¼ë²ˆì— í˜¸ì¶œ
        """
        for itype, cfg in ITEM_PROCESSORS.items():
            process_item_type(
                ws_id=ws_id,
                workspace_item_pending_pod=workspace_item_pending_pod,
                workspace_instance_used_resource=workspace_instance_used_resource,
                item_type=itype,
                get_item_list_fn=cfg["get_item_list_fn"],
                calculate_usage_fn=cfg["calculate_usage_fn"],
                get_limits_fn=cfg["get_limits_fn"],
                db_sync_fn=cfg["db_sync_fn"]
            )
            
    def deploy_pod_via_helm(pod_info):
        """
        í—¬ë¦„ ì‹¤í–‰ì„ í•œ ê³³ì—ì„œ ê´€ë¦¬.
        pod_type ë° work_func_type ë³„ë¡œ ê¸°ì¡´ ë¡œì§(create_* ë“±) í˜¸ì¶œ
        """
        res, message = None, None
        pt = pod_info.get("pod_type")
        if pt == TYPE.PROJECT_TYPE:
            wft = pod_info.get("work_func_type")
            if wft == TYPE.TRAINING_ITEM_A:
                res, message = create_training_pod(pod_info=pod_info)
            elif wft == TYPE.TRAINING_ITEM_B:
                res, message = create_project_tool(pod_info=pod_info)
            elif wft == TYPE.TRAINING_ITEM_C:
                res, message = create_hps_pod(pod_info=pod_info)

        elif pt == TYPE.DEPLOYMENT_TYPE:
            if settings.LLM_USED and pod_info.get("is_llm"):
                res, message = install_deployment_llm(pod_info=pod_info)
            else:
                res1, message = install_deployment_pod(deployment_info=pod_info)
                res2, message = install_deployment_svc_ing(deployment_info=pod_info)
                res = True if (res1 != False and res2 != False) else False

        elif pt == TYPE.PREPROCESSING_TYPE:
            wft = pod_info.get("work_func_type")
            if wft == TYPE.PREPROCESSING_ITEM_A:
                res, message = create_preprocessing_tool(pod_info=pod_info)
            elif wft == TYPE.PREPROCESSING_ITEM_B:
                res, message = create_preprocessing_job(pod_info=pod_info)

        elif pt == TYPE.COLLECT_TYPE:
            wft = pod_info.get("work_func_type")
            if wft == TYPE.PUBLICAPI_TYPE:
                res, message = create_public_api_collector(pod_info)
            elif wft == TYPE.REMOTESERVER_TYPE:
                print("RemoteServer Collector")
                res, message = create_remote_server_collector(pod_info)
            elif wft == TYPE.CRAWLING_TYPE:
                res, message = create_crawling_collector(pod_info)
            elif wft == TYPE.FB_DEPLOY_TYPE:
                res, message = create_fb_deployment_collector(pod_info)

        elif pt == TYPE.ANALYZER_TYPE:
            res, message = create_analyzer_pod(pod_info=pod_info)

        if settings.LLM_USED:
            if pt == TYPE.FINE_TUNING_TYPE:
                # LLM Fine Tuning
                # CPU, RAMì€ ì•„ë˜ì—ì„œ ì„¤ì • ê°€ëŠ¥
                res, message = create_fine_tuning(pod_info=pod_info)

        return res, message

    def revert_helm_on_failure(pod_info, workspace_id):
        """
        í—¬ë¦„ ë°°í¬ ì‹¤íŒ¨ ì‹œ rollback (ì‚¬ìš©ì ì½”ë“œì—ì„œ í•˜ë˜ ë¶€ë¶„)
        """
        try:
            if pod_info["pod_type"] == TYPE.DEPLOYMENT_TYPE:
                if settings.LLM_USED and pod_info.get("is_llm"):
                    uninstall_deployment_llm(
                        deployment_id=pod_info["deployment_id"],
                        llm_type=pod_info["llm_type"],
                        llm_id=pod_info["llm_id"]
                    )
                else:
                    uninstall_pod_deployment(
                        workspace_id=workspace_id,
                        deployment_id=pod_info["deployment_id"],
                        deployment_worker_id=pod_info["deployment_worker_id"]
                    )
            elif pod_info["pod_type"] == TYPE.PROJECT_TYPE:
                if pod_info["work_func_type"] == TYPE.TRAINING_ITEM_B:
                    delete_helm_project(
                        project_tool_type=TYPE.TOOL_TYPE[pod_info["tool_type"]],
                        project_tool_id=pod_info["id"],
                        workspace_id=workspace_id
                    )
                elif pod_info["work_func_type"] in [TYPE.TRAINING_ITEM_A, TYPE.TRAINING_ITEM_C]:
                    delete_helm_project(
                        project_tool_type=pod_info["work_func_type"],
                        project_tool_id=pod_info["id"],
                        workspace_id=workspace_id
                    )
            elif pod_info["pod_type"] == TYPE.PREPROCESSING_TYPE:
                wft = pod_info["work_func_type"]
                delete_helm_preprocessing(
                    preprocessing_tool_type=wft,
                    preprocessing_tool_id=pod_info["id"],
                    workspace_id=workspace_id
                )
            elif pod_info.get("pod_type") == TYPE.ANALYZER_TYPE:
                delete_helm_analyzer(pod_info=pod_info)
            if settings.LLM_USED and pod_info["pod_type"] == TYPE.FINE_TUNING_TYPE:
                delete_helm_fine_tuning(
                    model_id=pod_info["model_id"],
                    workspace_id=workspace_id
                )
        except Exception as e:
            traceback.print_exc()
            pass

    def process_instance_queue_item(
    redis_client,
    pod_info,
    instance,
    ws_id,
    workspace_instance_used_resource
    ):
        """
        1) DB Sync
        2) ì¸ìŠ¤í„´ìŠ¤ ìì› ì²´í¬(available vs needed)
        3) GPU/CPU/NPU ì²˜ë¦¬
        4) Helm ë°°í¬ (deploy_pod_via_helm)
        5) ì‹¤íŒ¨ì‹œ revert
        """
        # 1) DB Sync
        if not workspace_db_sync(pod_info):
            return Status.FAIL_PASS, "ì‚¬ìš©ì ì¤‘ì§€, ì‚­ì œëœ ìš”ì²­"

        # 2) ì¸ìŠ¤í„´ìŠ¤ ìì› ê³„ì‚°
        total_cpu = instance["instance_allocate"] * instance["cpu_allocate"]
        total_ram = instance["instance_allocate"] * instance["ram_allocate"]
        total_gpu = instance["instance_allocate"] * instance["gpu_allocate"]

        used_res = workspace_instance_used_resource.get(instance["instance_id"], {"cpu":0,"ram":0,"gpu":0})
        available_cpu = total_cpu - used_res["cpu"]
        available_ram = total_ram - used_res["ram"]
        available_gpu = total_gpu - used_res["gpu"]
        need_cpu = pod_info["resource"]["cpu"] * pod_info["pod_count"]
        need_ram = pod_info["resource"]["ram"] * pod_info["pod_count"]
        need_gpu = pod_info.get("gpu_count", 0)

        if (available_cpu < need_cpu) or (available_ram < need_ram) or (available_gpu < need_gpu):
            return Status.FAIL_RETRY, f"ìì› ë¶€ì¡± - instance id : {instance["instance_id"]} | CPU/RAM/GPU Available: {available_cpu}/{available_ram}/{available_gpu} | Need: {need_cpu}/{need_ram}/{need_gpu}"

        # 3) GPU / CPU / NPU ì²˜ë¦¬
        if need_gpu > 0:
            # GPU ë¡œì§
            free_workspace_gpu_count = (instance["instance_allocate"] * instance["gpu_allocate"]) - used_res["gpu"]
            if need_gpu > free_workspace_gpu_count:
                return Status.FAIL_RETRY, "Workspace GPU ìì› ë¶€ì¡±"

            instance_selector = f"instance_id={instance['instance_id']}"
            used_instance_gpu_uuid = get_used_gpu_uuid(label_select=instance_selector)

            gpu_cluster_auto = pod_info["gpu_cluster_auto"]
            gpu_select = pod_info.get("gpu_select", [])
            if gpu_cluster_auto and need_gpu > 1:
                # ì˜ˆ: ìë™ í´ëŸ¬ìŠ¤í„°ë§
                gpu_auto_cluster_case = pod_info["gpu_auto_cluster_case"]
                gpu_model_status = json.loads(redis_client.get(redis_key.GPU_INFO_RESOURCE))
                available_gpus = get_available_gpus_by_model(
                    model_name=instance["resource_name"], 
                    data=gpu_model_status, 
                    instance_id=instance["instance_id"]
                )
                # filter out used
                real_available_gpus = []
                for g in available_gpus:
                    if g["gpu_uuid"] not in used_instance_gpu_uuid:
                        real_available_gpus.append(g)
                if not real_available_gpus:
                    return Status.FAIL_RETRY, "GPU ì—†ìŒ"

                # ì˜ˆ: common.get_gpu_auto_select_new(...)
                auto_select = get_gpu_auto_select(
                    gpu_count=gpu_auto_cluster_case["gpu_count"],
                    pod_count=gpu_auto_cluster_case["server"],
                    gpu_data=real_available_gpus
                )
                if not auto_select:
                    return Status.FAIL_RETRY, "GPU auto select ì‹¤íŒ¨"
                # í´ëŸ¬ìŠ¤í„°ë§
                real_available_gpus = gpu_auto_clustering(
                    available_gpus=auto_select,
                    pod_per_gpu=gpu_auto_cluster_case["gpu_count"]
                )
                pod_info["available_gpus"] = real_available_gpus

            elif (not gpu_cluster_auto) and need_gpu > 1:
                # ìˆ˜ë™ í´ëŸ¬ìŠ¤í„°ë§
                gpu_cluster_status = True
                for g in gpu_select:
                    if g["gpu_uuid"] in used_instance_gpu_uuid:
                        gpu_cluster_status = False
                        break
                if not gpu_cluster_status:
                    return Status.FAIL_RETRY, "ìˆ˜ë™ í´ëŸ¬ìŠ¤í„°ë§ ì¶©ëŒ"
                # í´ëŸ¬ìŠ¤í„°ë§
                real_available_gpus = gpu_auto_clustering(
                    available_gpus=gpu_select,
                    pod_per_gpu=pod_info["pod_per_gpu"]
                )
                pod_info["available_gpus"] = real_available_gpus

            else:
                # need_gpu == 1 or other simple cases
                gpu_model_status = json.loads(redis_client.get(redis_key.GPU_INFO_RESOURCE))
                available_gpus = get_available_gpus_by_model(
                    model_name=instance["resource_name"],
                    data=gpu_model_status,
                    instance_id=instance["instance_id"]
                )
                # filter out used
                real_available_gpus = []
                for g in available_gpus:
                    if g["gpu_uuid"] not in used_instance_gpu_uuid:
                        real_available_gpus.append(g)
                if not real_available_gpus:
                    return Status.FAIL_RETRY, "GPU ì—†ìŒ"

                available_gpus = get_optimal_gpus(available_gpus, num_gpus=1)
                available_gpus = gpu_auto_clustering(available_gpus, pod_per_gpu=1)
                pod_info["available_gpus"] = available_gpus

        elif need_gpu == 0 and instance["instance_type"] == TYPE.INSTANCE_TYPE_GPU:
            # GPU ì¸ìŠ¤í„´ìŠ¤ì§€ë§Œ gpu_count=0
            node_list = db_node.get_node_instance_list(instance_id=instance["instance_id"])
            nodes = [n['node_name'] for n in node_list]
            weights = [n['instance_allocate'] for n in node_list]
            pod_info["available_node"] = random.choices(nodes, weights=weights, k=1)[0]

        # CPU ì¸ìŠ¤í„´ìŠ¤
        elif instance["instance_type"] == TYPE.INSTANCE_TYPE_CPU:
            node_list = db_node.get_node_instance_list(instance_id=instance["instance_id"])
            nodes = [n['node_name'] for n in node_list]
            weights = [n['instance_allocate'] for n in node_list]
            pod_info["available_node"] = random.choices(nodes, weights=weights, k=1)[0]
            pod_info["cpu_instance_name"] = instance["instance_name"]

        # NPU ì¸ìŠ¤í„´ìŠ¤
        elif instance["instance_type"] == TYPE.INSTANCE_TYPE_NPU:
            logging.info("NPU ì‚¬ìš©")
            pod_info["used_npu"] = True

        # 4) helm ë°°í¬
        res, message = deploy_pod_via_helm(pod_info)
        if not res:
            # rollback
            revert_helm_on_failure(pod_info, ws_id)
            return Status.FAIL_RETRY, message
        else:
            logging.info("helm ok")
            return Status.SUCCESS, "success"

    def print_pending_queue_pods(ws_id, workspace_item_pending_pod):
        """
        íŠ¹ì • ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì˜ pending pod ë° ì¸ìŠ¤í„´ìŠ¤ ëŒ€ê¸°ì—´ì„ ì •ë¦¬í•˜ì—¬ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜.
        - workspace_id: ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ID
        - workspace_name: ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì´ë¦„
        - workspace_item_pending_pod: Pendingëœ Pod ì •ë³´ ë”•ì…”ë„ˆë¦¬
        - workspace_instances: í•´ë‹¹ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """        
        # workspace_id = workspace["id"]
        # workspace_name = workspace["name"]
        
        logging.info("=" * 50)
        logging.info(f"ğŸŸ¢ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ #{ws_id} ") # [{workspace_name}]
        logging.info("=" * 50)

        has_pending = False  # Pending Podì´ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í”Œë˜ê·¸
        
        # ì›Œí¬ìŠ¤í˜ì´ìŠ¤ë³„ Pending Pod ê°œìˆ˜ ì¶œë ¥
        for pod_type, pending_dict in workspace_item_pending_pod.items():
            # print(pending_dict, file=sys.stderr)
            total_pending = sum(len(v) for v in pending_dict.values())
            if total_pending == 0:
                continue  # í•´ë‹¹ íƒ€ì…ì— pendingëœ podê°€ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€
            
            has_pending = True

            logging.info(f"ğŸ”¸ {pod_type} ({total_pending} pending)")
            for item_id, pod_infos in pending_dict.items():
                for pod_info in pod_infos:
                    instance_id = pod_info.get("instance_id", "N/A")
                    gpu_count = pod_info.get("gpu_count", 0)
                    cpu_limit = pod_info.get("resource", {}).get("cpu", "N/A")
                    ram_limit = pod_info.get("resource", {}).get("ram", "N/A")
                    logging.info(f"  - ID: {item_id} | Instance: {instance_id} | GPU: {gpu_count} | CPU: {cpu_limit} | RAM: {ram_limit}")

        if not has_pending:
            logging.info("âœ… í˜„ì¬ PENDING ìƒíƒœì¸ Podì´ ì—†ìŠµë‹ˆë‹¤.")

    global last_print_time
    consumer = Consumer(conf)
    kafka_admin = AdminClient(kafka_admin_conf)
    
    type_id_map = {
                TYPE.PROJECT_TYPE: "project_id",
                TYPE.DEPLOYMENT_TYPE: "deployment_id",
                TYPE.PREPROCESSING_TYPE: "preprocessing_id",
                TYPE.ANALYZER_TYPE: "analyzer_id",
                TYPE.COLLECT_TYPE: "collect_id",
                TYPE.FINE_TUNING_TYPE: "model_id" if settings.LLM_USED else None
            }
    
    while True:
        try:
            time.sleep(0.1)
            redis_client = get_redis_client()
            # workspace_list = db_workspace.get_workspace_list()

            # Kafka Consume Messages
            success = kafka_consume_msgs(consumer, kafka_admin, redis_client, type_id_map)
            if not success:
                # ì¬ìƒì„±
                consumer = Consumer(conf)
                kafka_admin = AdminClient(kafka_admin_conf)
                logging.info("Kafka consumer reinitialized.")
                time.sleep(3)
            
            # Pending Load
            workspace_pending_pod = redis_client.hgetall(redis_key.WORKSPACE_ITEM_PENDING_POD2)
            # print(workspace_pending_pod, file=sys.stderr)
            # for workspace in workspace_list:
            for ws_id, raw_pending in workspace_pending_pod.items():
                workspace_item_pending_pod = json.loads(raw_pending)
                #TODO
                # workspace instance queueì— ê°’ì´ ìˆê±°ë‚˜ instance queue =ì— ê°’ì´ ìˆì„ ê²½ìš°ì—ë§Œ ëŒ ìˆ˜ ìˆë„ë¡ ìˆ˜ì •
                
                # ì¤€ë¹„: instanceë³„ ìì› ì‚¬ìš©ëŸ‰ dict
                workspace_instance_used_resource = {}

                # 1) Project / Deployment / Preprocessing / Analyzer / Collector ë“± ê³µí†µ ì²˜ë¦¬
                process_all_item_types(
                    ws_id=ws_id,
                    workspace_item_pending_pod=workspace_item_pending_pod,
                    workspace_instance_used_resource=workspace_instance_used_resource
                )

                # pending ë°˜ì˜
                redis_client.hset(
                    redis_key.WORKSPACE_ITEM_PENDING_POD2,
                    ws_id,
                    json.dumps(workspace_item_pending_pod)
                )
                # Pending Pod Queue ìƒíƒœ ì¶œë ¥
                if DEBUG:
                    print_pending_queue_pods(ws_id, workspace_item_pending_pod)
                
                # 2) ì¸ìŠ¤í„´ìŠ¤ íì—ì„œ ì‹¤ì œ helm ë°°í¬ ì‹œë„
                # -----------------------------------------------------------------------
                workspace_instances = db_workspace.get_workspace_instance_list(workspace_id=ws_id)

                for instance in workspace_instances:
                    try:
                        instance_key = redis_key.WORKSPACE_INSTANCE_QUEUE.format(ws_id, instance["instance_id"])
                        redis_queue = RedisQueue(redis_client=redis_client, key=instance_key)
                        pod_info_queue = redis_queue.pop_nowait()
                        if not pod_info_queue:
                            continue
                        pod_info = json.loads(pod_info_queue)
                    except Exception as e:
                        logging.info("pod_info_queue ì—ëŸ¬")
                        continue
                    logging.info("POD INFO QUEUE : %s", pod_info)
                    # í†µí•© í•¨ìˆ˜ í˜¸ì¶œ â†’ DB sync, ìì› ì²´í¬, GPU ì²˜ë¦¬, helm ë°°í¬ê¹Œì§€ ìˆ˜í–‰
                    status, msg = process_instance_queue_item(
                        redis_client=redis_client,
                        pod_info=pod_info,
                        instance=instance,
                        ws_id=ws_id,
                        workspace_instance_used_resource=workspace_instance_used_resource
                    )
                    
                    # ìì› ë¶€ì¡± ë“±ìœ¼ë¡œ ì‹¤íŒ¨ ì‹œ â†’ ë‹¤ì‹œ íì— ë„£ì–´ë‘ê¸°
                    if status == Status.FAIL_RETRY:
                        logging.info(f"Instance Queue failed scheduling (retry): {msg}")
                        redis_queue.lput(json.dumps(pod_info))
                    elif status == Status.FAIL_PASS:
                        logging.info(f"Instance Queue failed scheduling (pass): {msg}")
                    else:
                        logging.info("Instance Queue scheduling success")
            # Pending Pod Queue ìƒíƒœ ì¶œë ¥
            # current_time = time.time()
            # if current_time - last_print_time >= PRINT_INTERVAL:
            #     workspace_pending = redis_client.hgetall(redis_key.WORKSPACE_ITEM_PENDING_POD2)
            #     for workspace in workspace_list:
            #         raw_pending = workspace_pending.get(workspace["id"])
            #         if raw_pending:
            #             workspace_item_pending_pod = json.loads(raw_pending)
            #         else:
            #             workspace_item_pending_pod = {
            #                 TYPE.PROJECT_TYPE: {},
            #                 TYPE.DEPLOYMENT_TYPE: {},
            #                 TYPE.PREPROCESSING_TYPE: {},
            #                 TYPE.ANALYZER_TYPE: {},
            #                 TYPE.COLLECT_TYPE: {},
            #                 TYPE.FINE_TUNING_TYPE: {},
            #             }
            #         print(f"3 {workspace["id"]} ", workspace_item_pending_pod, file=sys.stderr)
            #         print_pending_queue_pods(workspace, workspace_item_pending_pod)
            #     last_print_time = current_time
                
        except Exception as e:
            print(traceback.format_exc(), file=sys.stderr)